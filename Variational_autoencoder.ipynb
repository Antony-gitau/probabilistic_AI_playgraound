{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbecGN+O9AmegRLPj47//z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antony-gitau/probabilistic_AI_playgraound/blob/main/Variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "Generative models aim to learn the probability density function $p(x)$ \n",
        " (distribution probability) that best describes the training data to enable generation by sampling from the distribution.\n",
        "\n",
        " - sample generation: \n",
        " - density estimation:\n",
        "\n",
        "different strategy to achieve this goal:\n",
        "1. explicit density model - \n",
        "2. implicit density model - \n",
        "\n",
        "latent variable models:\n",
        "1. variational autoencoder\n",
        "2. Generative Adversarial Network\n",
        "\n",
        "**Autoencoder**\n",
        "\n",
        "- unsupervised learning approach\n",
        "- dimensionality of latent space \n",
        "- representation learning \n",
        "- self encoding or auto-encoding\n",
        "\n",
        "**variational autoencoder**\n",
        "- probability twist on autoencoder\n",
        "- loss function: \n",
        "encoder: f\n",
        "\n",
        "\n",
        "\n",
        "generation is the process of computing a data point $x$ from the latent variable $z$. \n",
        "\n",
        "maximum likelihood of the mean or standard deviation - estimation technique for parameters of a probability distribution so that the distribution fits the observed data. \n",
        "\n",
        "\n",
        "likelihood - finding the optimal values for the mean (or standard deviation) for a distribution given a bunch of observed measurements.\n",
        "\n",
        "approximation methods:\n",
        "1. markov chain monte carlo\n",
        "2. variational inference\n",
        "\n",
        "\n",
        "amortized variational inference - train an external neural network to predict the variational parameters instead of optimizing ELBO per data point.\n",
        "\n",
        "reparametarization - rewriting the the expectation so that the distribution is independent of the parameter $Î˜$\n",
        "\n",
        "**GAN**\n",
        "- conditional GAN\n",
        "- CycleGAN\n",
        "\n",
        "**Diffusion models**\n",
        "\n",
        "[good read](https://theaisummer.com/latent-variable-models/)\n",
        "\n",
        "[mit lecture](https://youtu.be/3G5hWM6jqPk?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI)\n",
        "\n",
        "In this notebook we will go into details on Variational Autoencoder with inspiration from [MIT'S Lab 2 on face detection](https://colab.research.google.com/drive/1j2W42n7R2DeBuO0xQZr7kDmTY2Z4Sexw#scrollTo=nLemS7dqECsI)\n",
        "\n",
        "![The concept of a VAE](https://i.ibb.co/3s4S6Gc/vae.jpg) this is the architectural design of a Variational Autoencoder (VAE).\n",
        "\n",
        "**encoder** transform inputs into variables, for example defined by mean and standard deviation, then draw from that distribution (defined by the mean and standard deviation) to generate a set of sampled latent variables.\n",
        "\n",
        "**decoder** the decoder's task is to reconstruct the latent variable to the original form of the input data. The decoder learns which latent variables are important. \n",
        "\n",
        "**goal of VAE** is therefore to train a model that learns a representation of the underlying latent space of the training data.\n",
        "\n",
        "**Loss function** \n",
        "- the encoder needs to learn latent variables which should ideally match the input (remember the input is transformed into a unit gaussian). this is the latent loss.\n",
        "\n",
        "- the decoder needs to reconstruct the latent variables clossly to the input. this is reconstruction loss.\n",
        "\n",
        "- so the total loss of a variational autoencoder is the sum of latent and reconstruction loss.\n"
      ],
      "metadata": {
        "id": "87ioSp15iAFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "YP-1pbtYXWGJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iXEbzH-Ch8xj"
      },
      "outputs": [],
      "source": [
        "def vae_loss_function(x, x_reconstructed, mu, logsigma, kl_weight = 0.005):\n",
        "  '''\n",
        "  we pass an input and its reconstruction.\n",
        "  we also define the prior distribution with mean and log of standard deviation\n",
        "  kl_weight is the weight parameter for the latent loss used for regularization\n",
        "  '''\n",
        "  latent_loss = 0.5 * tf.reduce_sum(tf.exp(logsigma) + tf.square(mu) -1 - logsigma, axis=-1)\n",
        "  abs_diff = tf.abs(x, x_reconstructed)\n",
        "  reconstruction_loss = tf.reduce_mean(abs_diff, axis=[1,2,3])\n",
        "  vae_loss = kl_weight * latent_loss + reconstruction_loss\n",
        "\n",
        "  return vae_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling and reparameterization"
      ],
      "metadata": {
        "id": "kKHYxZnbIHah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(z_mean, z_logsigma):\n",
        "  '''\n",
        "  we pass the mean and logarithm of variance of the learned latent variable\n",
        "  we extracts the batch size and the number of dimensions in the latent space\n",
        "  we then generate random samples from a standard normal distribution \n",
        "  the shape of the random sample is the same as the mean of latent variables\n",
        "  we compute the parameterization trick\n",
        "  '''\n",
        "  batch, latent_dim = z_mean.shape\n",
        "  epsilon = tf.random.normal(shape = (batch, latent_dim))\n",
        "  z = z_mean  + tf.exp(0.5 * z_logsigma) * epsilon\n",
        "\n",
        "  return z\n",
        "\n"
      ],
      "metadata": {
        "id": "aZC-4StWL-wY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semi-supervised variational autoencoder (SS-VAE)\n",
        "\n",
        "- the motivation is to use variational encoder to uncover bias in face recognition. \n",
        "- notice there is a supervised classification problem.\n",
        "- notice also that the VAE we talked about earlier did not output supervised variables.\n",
        "\n",
        "- lets workout a loss function"
      ],
      "metadata": {
        "id": "MeuJyhr5Q948"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ss_vae_loss_function(x, x_pred, y, y_logit, mu, logsigma):\n",
        "  '''\n",
        "  we pass an input, x, and its reconstruction, x_pred\n",
        "  we then pass a true label, y, and its prediction, y_logit\n",
        "  y_logits are the raw output before applying sigmoid function\n",
        "  we then pass the mean and log standard deviation of the learned latent distribution\n",
        "  '''\n",
        "  # we call the vae_loss function we defined earlier\n",
        "  vae_loss = vae_loss_function(x, x_pred, mu, logsigma, kl_weight = 0.005)\n",
        "  \n",
        "  # we then define classification loss \n",
        "  classification_loss = tf.nn.sigmoid_cross_entropy_with_logits(y_logit,y)\n",
        "  classification_loss = tf.reduce_mean(classification_loss)\n",
        "\n",
        "  # we create an indicator for which training data are images of faces\n",
        "  face_indicator = tf.cast(tf.equal(y, 1), tf.float32)\n",
        "\n",
        "  # total ss_vae loss\n",
        "  total_loss = vae_loss + face_indicator * classification_loss\n",
        "  total_loss = tf.reduce_mean(total_loss)\n",
        "\n",
        "  return total_loss, classification_loss, vae_loss\n"
      ],
      "metadata": {
        "id": "ej-ssxqhVsEn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we define the ss-vae architecture:\n",
        "\n",
        "- we will first define the encoder. that will entail supervised outputs from the classification and the number of latent variables from the encoder (latent variables are the output of the encoder)\n",
        "\n",
        "- Then we define the decoder. This is the part of the architecture that will output reconstruction.\n"
      ],
      "metadata": {
        "id": "k_ZV9lWIOa90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the CNN model ###\n",
        "import functools\n",
        "n_filters = 12 # base number of convolutional filters\n",
        "\n",
        "'''Function to define a standard CNN model'''\n",
        "def make_standard_classifier(n_outputs=1):\n",
        "  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "\n",
        "  model = tf.keras.Sequential([ \n",
        "    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "    \n",
        "    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Dense(n_outputs, activation=None),\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "standard_classifier = make_standard_classifier()"
      ],
      "metadata": {
        "id": "qUaP14B2VNTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Define the decoder portion of the SS-VAE ###\n",
        "\n",
        "def make_face_decoder_network(n_filters=12):\n",
        "\n",
        "  # Functionally define the different layer types we will use\n",
        "  Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding='same', activation='relu')\n",
        "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "  Flatten = tf.keras.layers.Flatten\n",
        "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "  Reshape = tf.keras.layers.Reshape\n",
        "\n",
        "  # Build the decoder network using the Sequential API\n",
        "  decoder = tf.keras.Sequential([\n",
        "    # Transform to pre-convolutional generation\n",
        "    Dense(units=4*4*6*n_filters),  # 4x4 feature maps (with 6N occurances)\n",
        "    Reshape(target_shape=(4, 4, 6*n_filters)),\n",
        "\n",
        "    # Upscaling convolutions (inverse of encoder)\n",
        "    Conv2DTranspose(filters=4*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=2*n_filters, kernel_size=3,  strides=2),\n",
        "    Conv2DTranspose(filters=1*n_filters, kernel_size=5,  strides=2),\n",
        "    Conv2DTranspose(filters=3, kernel_size=5,  strides=2),\n",
        "  ])\n",
        "\n",
        "  return decoder"
      ],
      "metadata": {
        "id": "VU_bg4V_VTiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we inherit a model class from keras to define an ss_vae loss\n",
        "class SS_VAE(tf.keras.Model):\n",
        "\n",
        "  # initialize the class SS_VAE and take the latent dim arguement\n",
        "  def __init__(self, latent_dim):\n",
        "    super(SS_VAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  #We accomodate the output of the latent variables and supervised outputs of classfication\n",
        "    num_encoder_dims = 2 * self.latent_dim + 1\n",
        "\n",
        "    # we create instances of neural networks models encoder and decoder\n",
        "    self.encoder = make_standard_classifier(num_encoder_dims)\n",
        "    self.decoder = make_face_decoder_network()\n",
        "\n",
        "\n",
        "    # we now define the function that feed the encoder with:\n",
        "    # latent space and classification probability\n",
        "\n",
        "    def encoder(self, x):\n",
        "      encoder_output = self.encoder(x)\n",
        "\n",
        "      y_logit = tf.expand_dims(encoder_output[:,0], -1)\n",
        "      z_mean = encoder_output[:,1:self.latent_dim+1]\n",
        "      z_logsigma = encoder_output[:, self.latent_dim+1:]\n",
        "\n",
        "      return y_logit, z_mean, z_logsigma\n",
        "\n",
        "    # we will then define decoding function\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "1rVLGT_5SBLf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}